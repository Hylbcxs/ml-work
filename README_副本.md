# ğŸ  å®¶åº­ç”µåŠ›æ¶ˆè€—å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ç³»ç»Ÿ

## ğŸ” é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®åŸºäº"Individual Household Electric Power Consumption"æ•°æ®é›†ï¼Œé’ˆå¯¹å®¶åº­æ€»æœ‰åŠŸåŠŸç‡è¿›è¡Œ**çŸ­æœŸ(90å¤©)**ä¸**é•¿æœŸ(365å¤©)**æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶ã€‚é‡‡ç”¨ä¸‰ç§å…ˆè¿›æ¨¡å‹ï¼š

- **LSTM**ï¼šæ•æ‰æ—¶åºä¾èµ–çš„å‘¨æœŸæ€§ä¸è¶‹åŠ¿  
  

- **Transformer**ï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºé•¿æœŸä¾èµ–å…³ç³»æŠŠæ¡  
  

- **MTLFS**ï¼šèåˆå¤šå°ºåº¦å·ç§¯ã€æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶å’Œæ··åˆè®°å¿†æ¨¡å—çš„åˆ›æ–°æ¨¡å‹  
  

## âš™ï¸ ç¯å¢ƒé…ç½®
æˆ‘ä»¬ä½¿ç”¨uvåŒ…è¿›è¡Œç®¡ç†
```
uv venv
source .venv/bin/activate
uv sync
```
## ğŸ“Š æ•°æ®é¢„å¤„ç†
### é¢„å¤„ç†è„šæœ¬
```
src/data_process/data_preprocessing.py
```
### å¤„ç†æµç¨‹
1. æ•°æ®è¯»å–ä¸åˆ—åè§„èŒƒåŒ–
2. ç‰¹æ®Šå€¼å¤„ç†ä¸æ—¥æœŸè§£æ
3. æ—¶é—´åºåˆ—å®Œæ•´æ€§å¤„ç†
4. ç¼ºå¤±å€¼å¤„ç†ï¼ˆæ—¶é—´æ„ŸçŸ¥æ’å€¼+åˆ—å‡å€¼å¡«å……ï¼‰
5. æŒ‰å¤©èšåˆæ•°æ®
6. å¤–éƒ¨å¤©æ°”æ•°æ®èåˆï¼ˆOpen-Meteo APIï¼‰
7. ç‰¹å¾å·¥ç¨‹ï¼ˆæå–å¤šç»´æ—¶é—´ç‰¹å¾ï¼‰

### ç‰¹å¾å·¥ç¨‹ç»“æœ
| ç±»å‹ | ç‰¹å¾æ•°é‡ | ç¤ºä¾‹ç‰¹å¾ |
|------|------|:----:|
| ç”µåŠ›ç‰¹å¾ | 7ä¸ª | æœ‰åŠŸ/æ— åŠŸåŠŸç‡ã€ç”µå‹ã€ç”µæµå¼ºåº¦ç­‰ |
| æ°”è±¡ç‰¹å¾ | 6ä¸ª | é™æ°´é‡ã€é›¾å¤©æ¬¡æ•°ç­‰ |
| æ¸©åº¦ç‰¹å¾ | 1ä¸ª | æ—¥å¹³å‡æ¸©åº¦ |
| æ—¶é—´ç‰¹å¾ | 6ä¸ª | å¹´ã€æœˆã€æ—¥ã€æ˜ŸæœŸå‡ ç­‰ |

## ğŸ§  æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹
### ğŸ”„ LSTMæ¨¡å‹
#### è®­ç»ƒè„šæœ¬
```
CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 ml-work/src/train.py \
    --model_type 'lstm' \
    --mode 'train' \
    --data_path 'ml-work/data' \
    --epochs 100 \
    --output_size 90 \
    --input_size 90 \
    --hidden_size 128 \
    --input_feature 14 \
    --output_feature 14 \
    --output_length 90 \
    --lr 1e-3 \
    --batch_size 8 \
    --print_every 10 \
    --seed 42 \
    --loss_type 'mse' \
    --log_file 'ml-work/logs' \
    --save_path 'ml-work/ckpts' \
    --figure_path 'ml-work/figures'
```
#### å…³é”®å‚æ•°
| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| **hidden_size** | LSTMéšè—å±‚å¤§å° | 128 |
| **teacher_forcing_ratio** | æ•™å¸ˆå¼ºåˆ¶æ¯”ä¾‹ | 0.7 |
| **bidirectional** | ä½¿ç”¨åŒå‘LSTM | True |

### âš¡ Transformeræ¨¡å‹
#### è®­ç»ƒè„šæœ¬
```
python ml-work/src/model/transformer/transformer.py
```
#### æ¨¡å‹ä¼˜åŠ¿
- è‡ªæ³¨æ„åŠ›æœºåˆ¶æ•æ‰é•¿æœŸä¾èµ–
- ä½ç½®ç¼–ç ä¿ç•™æ—¶åºä¿¡æ¯
- è‡ªé€‚åº”è¾“å‡ºç­–ç•¥
#### å…³é”®å‚æ•°
| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| **nhead** | æ³¨æ„åŠ›å¤´æ•° | 8 |
| **num_layers** | ç¼–ç å™¨å±‚æ•° | 3 |
| **dim_feedforward** | å‰é¦ˆç½‘ç»œç»´åº¦ | 512 |
| **output_strategy** | è¾“å‡ºç­–ç•¥(full_sequence/last_step) | full_sequence |

### ğŸš€ MTLFSæ”¹è¿›æ¨¡å‹
#### è®­ç»ƒå‘½ä»¤
```
CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 ml-work/src/train.py \
    --model_type 'mtlfs' \
    --mode 'train' \
    --data_path 'ml-work/data' \
    --epochs 100 \
    --output_size 365 \
    --input_size 90 \
    --hidden_size 512 \
    --input_feature 20 \
    --output_feature 1 \
    --cnn_channels 64 \
    --attn_heads 8 \
    --lr 1e-4 \
    --batch_size 32 \
    --dropout 0.1 \
    --weight_decay 1e-4 \
    --seed 42 \
    --log_file 'ml-work/logs' \
    --save_path 'ml-work/ckpts'
```
#### åˆ›æ–°æ¨¡å—ï¼šâ€‹â€‹
1. å¤šå°ºåº¦å·ç§¯(æ ¸å°ºå¯¸3/7/15)
2. æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶
3. LSTM-GRUæ··åˆè®°å¿†æ¨¡å—
4. ç‰¹å¾äº¤äº’æ¨¡å—

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
####  å‡æ–¹è¯¯å·®(MSE)
```
MSE = (1/n) * Î£(y_i - Å·_i)^2
```
#### å¹³å‡ç»å¯¹è¯¯å·®(MAE)
```
MAE = (1/n) * Î£|y_i - Å·_i|
```

### ğŸ“Š ç»“æœå¯¹æ¯”
| æ¨¡å‹ | çŸ­æœŸé¢„æµ‹(MSE) | é•¿æœŸé¢„æµ‹(MSE) | ç¨³å®šæ€§(Ïƒ) |
|------|---------------|---------------|-----------|
| LSTM | 0.07592 | 0.07735 | è¾ƒé«˜ |
| Transformer | 0.00801 | 0.00913 | **æœ€ä¼˜** |
| MTLFS | 0.01089 | 0.01008 | ä¸­ç­‰ |

