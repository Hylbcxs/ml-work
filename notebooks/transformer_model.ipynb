{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cee06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "class PowerDataset(Dataset):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # if args.mode == 'train':\n",
    "        df = pd.read_csv('/opt/data/private/hyl/code/ml-work/data/train_new.csv')\n",
    "        # elif args.mode == 'test':\n",
    "        #     df = pd.read_csv(args.data_path + '/test_new.csv')\n",
    "\n",
    "        # 数据清理\n",
    "        df.replace('?', np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.drop(columns=['DateTime'])\n",
    "        \n",
    "        # 使用MinMaxScaler进行标准化（范围0-1）\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.data = self.scaler.fit_transform(np.array(df))\n",
    "\n",
    "        # for i, col in enumerate(df.columns):\n",
    "        #     print(f\"  {col}: [{self.data[:, i].min():.3f}, {self.data[:, i].max():.3f}]\")\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.data_x = []\n",
    "        self.data_yin = []\n",
    "        self.data_yout = []\n",
    "        self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "        dataX = []\n",
    "        dataY = [] \n",
    "        dataY_in = []\n",
    "\n",
    "        # 将输入窗口的数据保存到X中，将输出窗口保存到Y中\n",
    "        window_size = self.input_size + self.output_size\n",
    "        for index in range(len(self.data) - window_size):\n",
    "            dataX.append(self.data[index: index + self.input_size][:])\n",
    "            dataY.append(self.data[index + self.input_size: index + window_size][:])\n",
    "        print(f\"生成了 {len(dataX)} 个训练样本\")\n",
    "        # start of sentence\n",
    "        SOS = np.zeros((1, 13))\n",
    "        \n",
    "        for i in range(len(dataY)):\n",
    "            dataY_in.append(np.concatenate((SOS, dataY[i][:-1,:]), axis=0)) # SOS+dataY[i](90,13)\n",
    "            \n",
    "        dataY_out = dataY\n",
    "        self.data_x = np.array(dataX)\n",
    "        self.data_yin = np.array(dataY_in)\n",
    "        self.data_yout = np.array(dataY_out)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 返回数据的总数\n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data_x[idx], dtype=torch.float32)\n",
    "        decoder_input = torch.tensor(self.data_yin[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.data_yout[idx], dtype=torch.float32)\n",
    "        return data, decoder_input, label\n",
    "    \n",
    "def dataloader():\n",
    "    raw_dataset = PowerDataset(input_size=90, output_size=90)\n",
    "    dataloader = DataLoader(raw_dataset, batch_size=8, drop_last=True)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11845e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成了 565 个训练样本\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataloader()\n",
    "for inputs, tgt_input, label in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beca933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(src, tgt):\n",
    "    # src: [bs, n]\n",
    "    # tgt: [bs, m-1]\n",
    "    def get_pad_mask(src):\n",
    "        return (src == 0).unsqueeze(-2).to('cuda') # [bs, 1, n] 在dim=1上广播\n",
    "    src_mask = get_pad_mask(src) # [bs, n, n]\n",
    "\n",
    "    def get_subsequent_mask(tgt): # 上三角矩阵\n",
    "        bs, len_q = tgt.size()\n",
    "        subsequent_mask = (torch.triu(torch.ones((1, len_q, len_q)), diagonal=1)).bool()\n",
    "        # triu(, diagonal=1) 保留主对角线上面一行，及其往上的全部\n",
    "        return subsequent_mask.to('cuda')\n",
    "    tgt_mask = get_pad_mask(tgt) | get_subsequent_mask(tgt) # decoder自己本来对句末padding的mask和遮蔽当前时刻后的mask叠加\n",
    "\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3185ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask, trg_mask = create_masks(torch.ones(8,90), torch.ones(8,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de800c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, n_head, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_attention_heads = n_head\n",
    "        self.head_dim = self.hidden_size // self.num_attention_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.k_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.v_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.droptout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def attention(self, q, k, v, head_dim, mask=None, dropout=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(head_dim) # (bs, h, -1, head_dim) * (bs, h, head_dim, -1) = （bs, h, n, n）\n",
    "\n",
    "        if mask is not None: # mask: (bs, n, n)\n",
    "            mask = mask.unsqueeze(1) # 在头维度进行一样的mask操作\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores) # what is the type of dropout?\n",
    "\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    def forward(self, hidden_states, mask=None):\n",
    "        # hidden_states.shape = [batch_size, seq_len, hidden_dim]\n",
    "        input_shape = hidden_states.shape[:-1] # [8, 90]\n",
    "        hidden_shape = (*input_shape, -1, self.head_dim) # (8, 90, -1, 64)\n",
    "        batch_size = hidden_states.size(0)\n",
    "\n",
    "        q = self.q_linear(hidden_states).view(hidden_shape).transpose(1, 2) # [8, 8, 90, 64]\n",
    "        k = self.k_linear(hidden_states).view(hidden_shape).transpose(1, 2)\n",
    "        v = self.v_linear(hidden_states).view(hidden_shape).transpose(1, 2)\n",
    "\n",
    "        attention_scores = self.attention(q, k, v, self.head_dim, mask, self.droptout)\n",
    "        concat = attention_scores.transpose(1, 2).contiguous().view(batch_size, -1, self.hidden_size)\n",
    "        return self.out(concat)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,hidden_size,eps):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "        return self.weight * hidden_states.to(input_dtype)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"{tuple(self.weight.shape)}, eps={self.variance_epsilon}\"\n",
    "    \n",
    "    # def forward(self, x):\n",
    "    #     norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "    #     return norm\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(hidden_size, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class PositionEmbedding(nn.Module):\n",
    "    '''\n",
    "    parameter: \n",
    "    input: sentence after embedding []\n",
    "    '''\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Matrix PE is a constant\n",
    "        pe = torch.zeros(output_size, self.hidden_size)\n",
    "        for pos in range(output_size):\n",
    "            for i in range(0, self.hidden_size, 2): # i = 0, 2,...,510\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / self.hidden_size)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / self.hidden_size)))\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 使得单词嵌入表示相对大一些\n",
    "        x = x * math.sqrt(self.hidden_size)\n",
    "\n",
    "        seq_len = x.size(1) # 90\n",
    "        x = x + Variable(self.pe[:,:seq_len], requires_grad=False).cuda()\n",
    "        return x\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.features = 13\n",
    "        self.embedding = nn.Linear(self.features, hidden_size)\n",
    "    \n",
    "    def forward(self, input_seq):\n",
    "\n",
    "        return self.embedding(input_seq) # to[8, 90, 512]\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size,eps, dropout, n_head, d_ff):\n",
    "        super().__init__()\n",
    "        self.input_layernorm = RMSNorm(hidden_size,eps)\n",
    "        self.cross_layernorm = RMSNorm(hidden_size,eps)\n",
    "        self.final_layernorm = RMSNorm(hidden_size,eps)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        self.self_attn = MultiHeadAttention(hidden_size, n_head, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(hidden_size, n_head, dropout)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, d_ff, dropout)\n",
    "\n",
    "    def forward(self, hidden_states, encoder_output, src_mask, tgt_mask): \n",
    "        residual = hidden_states\n",
    "        hidden_states = self.input_layernorm(hidden_states)\n",
    "        hidden_states = self.dropout_1(self.self_attn(hidden_states, tgt_mask))\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.cross_layernorm(hidden_states)\n",
    "        hidden_states = self.dropout_2(self.cross_attn(encoder_output, src_mask))\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.final_layernorm(hidden_states)\n",
    "        hidden_states = self.dropout_3(self.ffn(hidden_states))\n",
    "        hidden_states = residual + hidden_states\n",
    "        return hidden_states\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_decoder, hidden_size, eps, dropout, n_head, d_ff, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_decoder = n_decoder\n",
    "\n",
    "        # Embedding & Positional Encoding\n",
    "        self.embed_tokens = Embedder(hidden_size)\n",
    "        self.embed_positions = PositionEmbedding(hidden_size, output_size)\n",
    "\n",
    "        # Decoder Layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(hidden_size,eps, dropout, n_head, d_ff) for _ in range(self.n_decoder)\n",
    "        ])\n",
    "\n",
    "        self.norm = RMSNorm(hidden_size,eps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        encoder_output, tgt, inputs_mask, tgt_mask\n",
    "    ) -> torch.Tensor:\n",
    "        inputs_embeds = self.embed_tokens(tgt)\n",
    "\n",
    "        x = self.embed_positions(inputs_embeds)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, inputs_mask, tgt_mask)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size,eps, dropout, n_head, d_ff):\n",
    "        super().__init__()\n",
    "        self.norm_1 = RMSNorm(hidden_size,eps)\n",
    "        self.norm_2 = RMSNorm(hidden_size,eps)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.FFN = FeedForwardNetwork(hidden_size, d_ff, dropout)\n",
    "        self.MHA = MultiHeadAttention(hidden_size, n_head, dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x1 = self.norm_1(x) \n",
    "        x = x + self.dropout_1(self.MHA(x, src_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.FFN(x2))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, n_encoder, eps, dropout, n_head, d_ff, output_size):\n",
    "        super().__init__()\n",
    "        self.n_encoder = n_encoder\n",
    "        self.embed = Embedder(hidden_size)\n",
    "        self.pe = PositionEmbedding(hidden_size, output_size)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hidden_size,eps, dropout, n_head, d_ff) for i in range(n_encoder)])\n",
    "        self.norm_last = RMSNorm(hidden_size=hidden_size, eps=eps)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.n_encoder):\n",
    "            x = self.layers[i](x, src_mask)\n",
    "        return self.norm_last(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b42ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, hidden_size, n_encoder, eps, dropout, n_head, d_ff, output_size):\n",
    "        super().__init__()\n",
    "        self.Encoder = Encoder(hidden_size, n_encoder, eps, dropout, n_head, d_ff, output_size)\n",
    "        self.Decoder = Decoder(n_decoder = n_encoder, hidden_size= hidden_size, eps=eps, dropout=dropout, n_head=n_head, d_ff=d_ff, output_size=output_size)\n",
    "        self.out = nn.Linear(hidden_size, 13)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_outputs = self.Encoder(src, src_mask)\n",
    "        decoder_outputs = self.Decoder(encoder_outputs, tgt, src_mask, tgt_mask)\n",
    "        outputs = self.out(decoder_outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "976bc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(hidden_size=512, n_encoder=6, eps=1e-6, dropout=0.1, n_head=8, d_ff=2048, output_size=90).to(device)\n",
    "for inputs, tgt_input, label in train_dataloader:\n",
    "    tgt_input = tgt_input.float().to(device) # [8, 90, 13]\n",
    "    inputs = inputs.float().to(device) # [8, 90, 13]\n",
    "    label = label.float().to(device) # [8, 90, 13]\n",
    "\n",
    "    input_mask, trg_mask = create_masks(torch.ones(8,90), torch.ones(8,90)) # input_mask:[8, 1, 90]\n",
    "    outputs = model(inputs, tgt_input, input_mask, trg_mask)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
