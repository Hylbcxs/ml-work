import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from sklearn.preprocessing import StandardScaler, MinMaxScaler

class PowerDataset(Dataset):
    def __init__(self, args):
        if args.mode == 'train':
            df = pd.read_csv(args.data_path + '/train_new.csv')
        elif args.mode == 'test':
            df = pd.read_csv(args.data_path + '/test_new.csv')

        # æ•°æ®æ¸…ç†
        df.replace('?', np.nan, inplace=True)
        df.dropna(inplace=True)
        df = df.drop(columns=['DateTime'])
        
        # ä½¿ç”¨MinMaxScalerè¿›è¡Œæ ‡å‡†åŒ–ï¼ˆèŒƒå›´0-1ï¼‰
        self.scaler = MinMaxScaler()
        self.data = self.scaler.fit_transform(np.array(df))
        
        print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {self.data.shape}")
        print(f"ğŸ“Š æ•°æ®èŒƒå›´: [{self.data.min():.3f}, {self.data.max():.3f}]")
        print(f"ğŸ“Š å„ç‰¹å¾ç»Ÿè®¡:")
        for i, col in enumerate(df.columns):
            print(f"  {col}: [{self.data[:, i].min():.3f}, {self.data[:, i].max():.3f}]")

        self.input_size = args.input_size
        self.output_size = args.output_size

        self.data_x = []
        self.data_yin = []
        self.data_yout = []
        self.split_data(args)

    def split_data(self, args):
        dataX = []  # ä¿å­˜X
        dataY = []  # ä¿å­˜Y

        # å°†è¾“å…¥çª—å£çš„æ•°æ®ä¿å­˜åˆ°Xä¸­ï¼Œå°†è¾“å‡ºçª—å£ä¿å­˜åˆ°Yä¸­
        window_size = self.input_size + self.output_size
        for index in range(len(self.data) - window_size):
            dataX.append(self.data[index: index + self.input_size][:])
            dataY.append(self.data[index + self.input_size: index + window_size][:])
        print(f"ğŸ“Š ç”Ÿæˆäº† {len(dataX)} ä¸ªè®­ç»ƒæ ·æœ¬")

        self.data_x = np.array(dataX)
        self.data_y = np.array(dataY)
    
    def __len__(self):
        # è¿”å›æ•°æ®çš„æ€»æ•°
        return len(self.data_x)
    
    def __getitem__(self, idx):
        data = torch.tensor(self.data_x[idx])
        label = torch.tensor(self.data_y[idx])
        return data, label
    
def dataloader(args):
    raw_dataset = PowerDataset(args)
    if args.mode == 'train':
        sampler = DistributedSampler(raw_dataset)
        dataloader = DataLoader(raw_dataset, batch_size=args.batch_size, sampler=sampler, drop_last=True)
    else:
        dataloader = DataLoader(raw_dataset, shuffle=True, batch_size=args.batch_size, drop_last=True) # å•å¡

    return dataloader