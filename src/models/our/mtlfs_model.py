import torch
from torch import nn
import torch.nn.functional as F
from torch.autograd import Variable
import math
from typing import Optional

class MultiScaleCNN_TimeSeries(nn.Module):
    def __init__(self, input_feature, hidden_size, kernel_sizes=[3, 7, 15], dropout=0.3):
        super(MultiScaleCNN_TimeSeries, self).__init__()
        
        # ä½¿ç”¨å¤šä¸ªå·ç§¯æ ¸æ¥æ„å»ºå¤šå°ºåº¦å·ç§¯æ¨¡å—
        # æ³¨æ„ï¼šæˆ‘ä»¬å°†å·ç§¯æ²¿ç€æ—¶é—´æ­¥(seq_len)è¿›è¡Œåº”ç”¨
        self.conv1 = nn.Conv1d(input_feature, hidden_size, kernel_size=kernel_sizes[0], padding=kernel_sizes[0] // 2)
        self.conv2 = nn.Conv1d(input_feature, hidden_size, kernel_size=kernel_sizes[1], padding=kernel_sizes[1] // 2)
        self.conv3 = nn.Conv1d(input_feature, hidden_size, kernel_size=kernel_sizes[2], padding=kernel_sizes[2] // 2)

        # Batch normalization å’Œ Dropout å±‚
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.bn2 = nn.BatchNorm1d(hidden_size)
        self.bn3 = nn.BatchNorm1d(hidden_size)
        self.dropout = nn.Dropout(dropout)
        
        self.residual_proj = nn.Linear(input_feature, hidden_size * 3)

    def forward(self, x):
        residual = self.residual_proj(x)
        # x.shape = [batch_size, seq_len, input_size] --> [batch_size, input_size, seq_len] for Conv1D
        x = x.transpose(1, 2)  # è½¬æ¢ä¸º [batch_size, input_size, seq_len]

        # è®¡ç®—æ¯ä¸ªå·ç§¯å±‚çš„è¾“å‡º
        x1 = F.gelu(self.bn1(self.conv1(x)))  # å·ç§¯æ“ä½œ
        x2 = F.gelu(self.bn2(self.conv2(x)))  
        x3 = F.gelu(self.bn3(self.conv3(x)))  

        # åˆå¹¶ä¸‰ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾
        x_concat = torch.cat([x1, x2, x3], dim=1)  # åœ¨é€šé“ç»´åº¦æ‹¼æ¥

        # å¯¹æ‹¼æ¥åçš„ç‰¹å¾åº”ç”¨ Dropout
        x_concat = self.dropout(x_concat)
        x_concat = x_concat.transpose(1, 2)

        output = x_concat + residual
        return self.dropout(output)

class TemporalAttentionModule(nn.Module):
    """æ¨¡å—2: æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—"""
    
    def __init__(self, input_dim, hidden_size, seq_len):
        super().__init__()
        
        self.input_dim = input_dim
        self.hidden_size = hidden_size
        self.seq_len = seq_len
        
        # å¤šå¤´æ³¨æ„åŠ›
        self.multihead_attn = nn.MultiheadAttention(
            embed_dim=input_dim,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = self._generate_pos_encoding(seq_len, input_dim)
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norm1 = nn.LayerNorm(input_dim)
        self.layer_norm2 = nn.LayerNorm(input_dim)
        
        # å‰é¦ˆç½‘ç»œ
        self.ffn = nn.Sequential(
            nn.Linear(input_dim, hidden_size * 4),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 4, input_dim)
        )
        # ğŸ”§ æ·»åŠ ç»´åº¦æŠ•å½±å±‚ï¼š768 â†’ 256
        self.output_projection = nn.Linear(input_dim, hidden_size)
        
    def _generate_pos_encoding(self, seq_len, d_model):
        pos_encoding = torch.zeros(seq_len, d_model)
        position = torch.arange(0, seq_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                           -(math.log(10000.0) / d_model))
        
        pos_encoding[:, 0::2] = torch.sin(position * div_term)
        pos_encoding[:, 1::2] = torch.cos(position * div_term)
        
        return nn.Parameter(pos_encoding.unsqueeze(0), requires_grad=False)
    
    def forward(self, x):
        # æ·»åŠ ä½ç½®ç¼–ç 
        x = x + self.pos_encoding[:, :x.size(1), :]
        
        # å¤šå¤´è‡ªæ³¨æ„åŠ›
        attn_output, _ = self.multihead_attn(x, x, x)
        x = self.layer_norm1(x + attn_output)
        
        # å‰é¦ˆç½‘ç»œ
        ffn_output = self.ffn(x)
        x = self.layer_norm2(x + ffn_output)

        # ğŸ”§ é™ç»´æŠ•å½±ï¼š768 â†’ 256
        x = self.output_projection(x)
        
        return x

class LSTMGRUFusionModule(nn.Module):
    """æ¨¡å—3: é•¿çŸ­æœŸè®°å¿†èåˆæ¨¡å—"""
    
    def __init__(self, input_size, hidden_size, dropout=0.1):
        super().__init__()
        
        # LSTMç”¨äºé•¿æœŸä¾èµ–
        self.lstm = nn.LSTM(
            input_size, hidden_size, 
            num_layers=2, batch_first=True, 
            dropout=dropout, bidirectional=True
        )
        
        # GRUç”¨äºçŸ­æœŸæ¨¡å¼
        self.gru = nn.GRU(
            input_size, hidden_size,
            num_layers=2, batch_first=True,
            dropout=dropout, bidirectional=True
        )
        
        # èåˆæƒé‡å­¦ä¹ 
        self.fusion_gate = nn.Sequential(
            nn.Linear(hidden_size * 4, hidden_size * 4),
            nn.Sigmoid()
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(hidden_size * 4, hidden_size)
        
    def forward(self, x):
        # LSTMè¾“å‡º
        lstm_out, _ = self.lstm(x)
        
        # GRUè¾“å‡º
        gru_out, _ = self.gru(x)
        
        # ç‰¹å¾èåˆ
        combined = torch.cat([lstm_out, gru_out], dim=-1)
        
        # å­¦ä¹ èåˆæƒé‡
        fusion_weights = self.fusion_gate(combined)
        
        # åŠ æƒèåˆ
        fused = combined * fusion_weights
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_proj(fused)
        
        return output

class FeatureInteractionModule(nn.Module):
    """æ¨¡å—4: ç‰¹å¾äº¤äº’æ¨¡å—"""
    
    def __init__(self, input_size, hidden_size, dropout=0.1):
        super().__init__()
        
        # è‡ªäº¤äº’å±‚
        self.self_interaction = nn.MultiheadAttention(
            embed_dim=input_size,
            num_heads=4,
            dropout=dropout,
            batch_first=True
        )
        
        # è·¨æ—¶é—´æ­¥äº¤äº’
        self.temporal_conv = nn.Conv1d(
            input_size, hidden_size,
            kernel_size=5, padding=2
        )
        
        # ç‰¹å¾é‡è¦æ€§è¯„ä¼°
        self.importance_net = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(hidden_size, hidden_size // 4),
            nn.ReLU(),
            nn.Linear(hidden_size // 4, hidden_size),
            nn.Sigmoid()
        )
        
        self.layer_norm = nn.LayerNorm(hidden_size)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # è‡ªäº¤äº’
        attn_out, _ = self.self_interaction(x, x, x)
        
        # è·¨æ—¶é—´æ­¥äº¤äº’
        conv_out = self.temporal_conv(attn_out.transpose(1, 2))
        conv_out = conv_out.transpose(1, 2)
        
        # ç‰¹å¾é‡è¦æ€§åŠ æƒ
        importance_weights = self.importance_net(conv_out.transpose(1, 2))
        importance_weights = importance_weights.unsqueeze(1)
        
        weighted_features = conv_out * importance_weights
        
        # æ®‹å·®è¿æ¥å’Œå½’ä¸€åŒ–
        output = self.layer_norm(weighted_features)
        
        return self.dropout(output)

class SimplePredictionHead(nn.Module):
    def __init__(self, input_size, pred_len, output_features=14):
        super().__init__()
        self.predictor = nn.Sequential(
            nn.Linear(input_size, input_size * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(input_size * 2, pred_len * output_features)
        )
        self.pred_len = pred_len
        self.output_features = output_features
        
    def forward(self, x, target=None):
        # å…¨å±€å¹³å‡æ± åŒ–
        global_feat = torch.mean(x, dim=1)  # [batch, hidden_size]
        
        # é¢„æµ‹
        pred = self.predictor(global_feat)  # [batch, pred_len * output_features]
        pred = pred.view(-1, self.pred_len, self.output_features)
        
        return pred
    """
    æ”¹è¿›çš„åºåˆ—åˆ°åºåˆ—é¢„æµ‹å¤´
    - æ”¯æŒTeacher Forcingè®­ç»ƒ
    - ä½¿ç”¨åŒå‘ç¼–ç å™¨
    - æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶
    - è§£å†³ç»´åº¦åŒ¹é…é—®é¢˜
    """
    # def __init__(self, input_size, pred_len, output_features, hidden_size=None):
    #     super().__init__()
    #     self.pred_len = pred_len
    #     self.output_features = output_features
    #     self.input_size = input_size
    #     self.hidden_size = hidden_size or input_size
        
    #     # ç¼–ç å™¨ï¼šåŒå‘LSTMè·å–æ›´å¥½çš„ä¸Šä¸‹æ–‡è¡¨ç¤º
    #     self.encoder = nn.LSTM(
    #         input_size=input_size,
    #         hidden_size=self.hidden_size,
    #         num_layers=2,
    #         batch_first=True,
    #         dropout=0.1,
    #         bidirectional=True
    #     )
        
    #     # è§£ç å™¨ï¼šå•å‘LSTMç”Ÿæˆæœªæ¥åºåˆ—
    #     self.decoder = nn.LSTM(
    #         input_size=output_features,  # è§£ç å™¨è¾“å…¥æ˜¯ç›®æ ‡ç‰¹å¾ç»´åº¦
    #         hidden_size=self.hidden_size * 2,  # åŒ¹é…åŒå‘ç¼–ç å™¨çš„è¾“å‡º
    #         num_layers=2,
    #         batch_first=True,
    #         dropout=0.1
    #     )
        
    #     # çŠ¶æ€è½¬æ¢å±‚ï¼šå°†åŒå‘ç¼–ç å™¨çŠ¶æ€è½¬ä¸ºå•å‘è§£ç å™¨çŠ¶æ€
    #     self.hidden_transform = nn.Linear(self.hidden_size * 2, self.hidden_size * 2)
    #     self.cell_transform = nn.Linear(self.hidden_size * 2, self.hidden_size * 2)
        
    #     # è¾“å‡ºæŠ•å½±å±‚
    #     self.output_proj = nn.Sequential(
    #         nn.Linear(self.hidden_size * 2, self.hidden_size),
    #         nn.ReLU(),
    #         nn.Dropout(0.1),
    #         nn.Linear(self.hidden_size, output_features)
    #     )
        
    #     # è¾“å…¥ç‰¹å¾è½¬æ¢å±‚ï¼ˆç”¨äºå¤„ç†ç»´åº¦ä¸åŒ¹é…ï¼‰
    #     if input_size != output_features:
    #         self.feature_transform = nn.Linear(input_size, output_features)
    #     else:
    #         self.feature_transform = nn.Identity()
            
    #     # åˆå§‹åŒ–æƒé‡
    #     self._init_weights()
    
    # def _init_weights(self):
    #     """LSTMæƒé‡åˆå§‹åŒ–"""
    #     for name, param in self.named_parameters():
    #         if 'weight_ih' in name:
    #             nn.init.xavier_uniform_(param.data)
    #         elif 'weight_hh' in name:
    #             nn.init.orthogonal_(param.data)
    #         elif 'bias' in name:
    #             param.data.fill_(0)
    #             # LSTM forget gate bias è®¾ä¸º1
    #             if 'bias_ih' in name:
    #                 n = param.size(0)
    #                 param.data[n//4:n//2].fill_(1.)
    
    # def forward(self, x, target=None):
    #     """
    #     å‰å‘ä¼ æ’­
    #     Args:
    #         x: ç¼–ç å™¨è¾“å…¥ [batch_size, seq_len, input_size]
    #         target: è§£ç å™¨ç›®æ ‡ [batch_size, pred_len, output_features]ï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
    #     Returns:
    #         predictions: [batch_size, pred_len, output_features]
    #     """
    #     batch_size = x.size(0)
        
    #     # 1. ç¼–ç é˜¶æ®µ
    #     encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder(x)
        
    #     # 2. çŠ¶æ€è½¬æ¢ï¼šåŒå‘ -> å•å‘
    #     # encoder_hidden: [4, batch, hidden_size] -> [2, batch, hidden_size*2]
    #     encoder_hidden = encoder_hidden.view(2, 2, batch_size, self.hidden_size)
    #     encoder_hidden = torch.cat([encoder_hidden[:, 0, :, :], encoder_hidden[:, 1, :, :]], dim=2)
        
    #     encoder_cell = encoder_cell.view(2, 2, batch_size, self.hidden_size)  
    #     encoder_cell = torch.cat([encoder_cell[:, 0, :, :], encoder_cell[:, 1, :, :]], dim=2)
        
    #     # åº”ç”¨çŠ¶æ€è½¬æ¢
    #     decoder_hidden = self.hidden_transform(encoder_hidden)
    #     decoder_cell = self.cell_transform(encoder_cell)
        
    #     # 3. è§£ç é˜¶æ®µ
    #     predictions = []
        
    #     # åˆå§‹è§£ç å™¨è¾“å…¥ï¼šä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥å¹¶è½¬æ¢ç»´åº¦
    #     last_input = x[:, -1:, :]  # [batch_size, 1, input_size]
    #     decoder_input = self.feature_transform(last_input)  # [batch_size, 1, output_features]
        
    #     for t in range(self.pred_len):
    #         # LSTMè§£ç 
    #         decoder_output, (decoder_hidden, decoder_cell) = self.decoder(
    #             decoder_input, (decoder_hidden, decoder_cell)
    #         )
            
    #         # ç”Ÿæˆé¢„æµ‹
    #         pred = self.output_proj(decoder_output)  # [batch_size, 1, output_features]
    #         predictions.append(pred)
            
    #         # å‡†å¤‡ä¸‹ä¸€æ—¶é—´æ­¥è¾“å…¥
    #         if self.training and target is not None and t < self.pred_len - 1:
    #             # è®­ç»ƒæ—¶ï¼šéšæœºä½¿ç”¨Teacher Forcing
    #             use_teacher_forcing = torch.rand(1).item() < 0.7
    #             if use_teacher_forcing:
    #                 decoder_input = target[:, t:t+1, :]
    #             else:
    #                 decoder_input = pred.detach()  # ä½¿ç”¨é¢„æµ‹å€¼ï¼Œé˜»æ–­æ¢¯åº¦
    #         else:
    #             # æ¨ç†æ—¶ï¼šä½¿ç”¨æ¨¡å‹é¢„æµ‹
    #             decoder_input = pred
        
    #     # åˆå¹¶æ‰€æœ‰é¢„æµ‹
    #     output = torch.cat(predictions, dim=1)  # [batch_size, pred_len, output_features]
    #     return output

class MTLFS_Model(nn.Module):
    """
    å¤šæ¨¡å—è‡ªé€‚åº”æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ (Multi-Module Adaptive Time Series Forecasting)
    
    æ¨¡å—ç»„æˆï¼š
    1. å¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å— (Multi-scale Feature Extraction)
    2. æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶æ¨¡å— (Temporal Attention)
    3. é•¿çŸ­æœŸè®°å¿†èåˆæ¨¡å— (LSTM-GRU Fusion)
    4. ç‰¹å¾äº¤äº’æ¨¡å— (Feature Interaction)
    5. è‡ªé€‚åº”é¢„æµ‹å¤´æ¨¡å— (Adaptive Prediction Head)
    """
    
    def __init__(self, 
                 input_feature=14, 
                 hidden_size=256, 
                 input_size=90,
                 output_size=90,
                 dropout=0.1):
        super(MTLFS_Model, self).__init__()
        
        self.input_feature = input_feature
        self.hidden_size = hidden_size
        self.input_size = input_size
        self.output_size = output_size
        
        # æ¨¡å—1: å¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å—
        self.multi_scale_extractor = MultiScaleCNN_TimeSeries(
            input_feature, hidden_size, dropout=dropout
        )
        
        # æ¨¡å—2: æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—
        self.temporal_attention = TemporalAttentionModule(
            hidden_size * 3, hidden_size, input_size
        )
        
        # æ¨¡å—3: é•¿çŸ­æœŸè®°å¿†èåˆæ¨¡å—
        self.memory_fusion = LSTMGRUFusionModule(
            hidden_size, hidden_size, dropout
        )
        
        # æ¨¡å—4: ç‰¹å¾äº¤äº’æ¨¡å—
        self.feature_interaction = FeatureInteractionModule(
            hidden_size, hidden_size, dropout
        )
        
        # ä½¿ç”¨Seq2Seqé¢„æµ‹å¤´
        # self.seq2seq_predictor = Seq2SeqPredictionHead(
        #     input_size=hidden_size,
        #     pred_len=output_size,
        #     output_features=14,
        #     hidden_size=hidden_size//2
        # )
        self.simple_predictor = SimplePredictionHead(input_size=hidden_size,
            pred_len=output_size,
            output_features=14)
        
    def forward(self, x, prediction_type='short'):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è¾“å…¥æ•°æ® [batch_size, seq_len, input_size]
            prediction_type: 'short' for 90å¤©é¢„æµ‹, 'long' for 365å¤©é¢„æµ‹
        """
        # æ¨¡å—1: å¤šå°ºåº¦ç‰¹å¾æå–
        multi_scale_features = self.multi_scale_extractor(x)
        
        # æ¨¡å—2: æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶
        attended_features = self.temporal_attention(multi_scale_features)
        
        # æ¨¡å—3: é•¿çŸ­æœŸè®°å¿†èåˆ
        memory_features = self.memory_fusion(attended_features)
        
        # æ¨¡å—4: ç‰¹å¾äº¤äº’
        interaction_features = self.feature_interaction(memory_features)
        
        # æ¨¡å—5: è‡ªé€‚åº”é¢„æµ‹
        predictions = self.simple_predictor(interaction_features)
        
        return predictions